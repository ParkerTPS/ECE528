{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "opdFPDUIUwFr",
    "outputId": "9b51c58d-62c3-46b1-8ca7-d1548d6aac9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "#tf version should be 2.2 or higher\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "      keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale model\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model\n",
    "model.compile(optimizer='sgd',\n",
    "          loss='sparse_categorical_crossentropy',\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 1s 621us/step - loss: 0.7727 - accuracy: 0.8171\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 617us/step - loss: 0.4560 - accuracy: 0.8808\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.4034 - accuracy: 0.8914\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 632us/step - loss: 0.3769 - accuracy: 0.8967\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.3600 - accuracy: 0.9006\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.3482 - accuracy: 0.9039\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 717us/step - loss: 0.3392 - accuracy: 0.9054\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.3320 - accuracy: 0.9078\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 631us/step - loss: 0.3262 - accuracy: 0.9088\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 631us/step - loss: 0.3212 - accuracy: 0.9102\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 640us/step - loss: 0.3170 - accuracy: 0.9118\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 630us/step - loss: 0.3134 - accuracy: 0.9125\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 631us/step - loss: 0.3101 - accuracy: 0.9132\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.3072 - accuracy: 0.9145\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.3047 - accuracy: 0.9153\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 644us/step - loss: 0.3024 - accuracy: 0.9159\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.3003 - accuracy: 0.9167\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.2984 - accuracy: 0.9169\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 626us/step - loss: 0.2966 - accuracy: 0.9173\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.2949 - accuracy: 0.9175\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 633us/step - loss: 0.2934 - accuracy: 0.9185\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 639us/step - loss: 0.2920 - accuracy: 0.9190\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 634us/step - loss: 0.2906 - accuracy: 0.9190\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 1s 628us/step - loss: 0.2893 - accuracy: 0.9195\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.2882 - accuracy: 0.9197\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.2871 - accuracy: 0.9203\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 616us/step - loss: 0.2861 - accuracy: 0.9204\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.2850 - accuracy: 0.9207\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.2842 - accuracy: 0.9208\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 608us/step - loss: 0.2831 - accuracy: 0.9211\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.2821 - accuracy: 0.9213\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 614us/step - loss: 0.2815 - accuracy: 0.9214\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 608us/step - loss: 0.2806 - accuracy: 0.9218\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.2799 - accuracy: 0.9222\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.2792 - accuracy: 0.9224\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 1s 609us/step - loss: 0.2785 - accuracy: 0.9222\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 1s 601us/step - loss: 0.2778 - accuracy: 0.9228\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 1s 602us/step - loss: 0.2771 - accuracy: 0.9225\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 1s 608us/step - loss: 0.2765 - accuracy: 0.9228\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 1s 613us/step - loss: 0.2760 - accuracy: 0.9234\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 1s 606us/step - loss: 0.2754 - accuracy: 0.9232\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 1s 601us/step - loss: 0.2748 - accuracy: 0.9236\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 1s 610us/step - loss: 0.2743 - accuracy: 0.9237\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 1s 602us/step - loss: 0.2738 - accuracy: 0.9243\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 1s 612us/step - loss: 0.2734 - accuracy: 0.9241\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.2729 - accuracy: 0.9240\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 1s 604us/step - loss: 0.2724 - accuracy: 0.9244\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 1s 606us/step - loss: 0.2718 - accuracy: 0.9247\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 1s 605us/step - loss: 0.2714 - accuracy: 0.9244\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 1s 607us/step - loss: 0.2710 - accuracy: 0.9251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x230824f2a90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "#model will be trained on 1875 batches of 32 images each; 1875*32 = 60000 images\n",
    "#The default batch size in model.fit is 32\n",
    "model.fit(train_images, train_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 607us/step - loss: 0.2727 - accuracy: 0.9235\n",
      "\n",
      "Test accuracy: 0.9235000014305115\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_images[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.5850942e-05, 2.4016378e-09, 1.4538353e-04, 4.2583984e-03,\n",
       "        1.2495250e-06, 3.1581465e-05, 4.9010889e-09, 9.9514008e-01,\n",
       "        2.4749954e-05, 3.6278789e-04],\n",
       "       [2.0730048e-03, 7.0565216e-06, 9.7129637e-01, 3.4495890e-03,\n",
       "        9.5618367e-11, 8.5884677e-03, 1.2980832e-02, 1.8365177e-12,\n",
       "        1.6045315e-03, 2.2074638e-09],\n",
       "       [4.3561558e-06, 9.7191846e-01, 1.4889522e-02, 2.9986526e-03,\n",
       "        1.6349067e-04, 1.5299196e-03, 1.5405227e-03, 3.5133762e-03,\n",
       "        3.0690348e-03, 3.7258648e-04],\n",
       "       [9.9963403e-01, 4.0763937e-11, 1.0730594e-04, 6.0189586e-06,\n",
       "        1.9136813e-08, 1.2277522e-04, 9.0750662e-05, 1.1551558e-05,\n",
       "        1.8808145e-05, 8.7737417e-06],\n",
       "       [3.9974679e-04, 1.2313155e-06, 3.9578481e-03, 6.9017864e-05,\n",
       "        9.6379507e-01, 3.4714610e-04, 2.4575705e-03, 4.9257576e-03,\n",
       "        3.2889692e-03, 2.0757739e-02],\n",
       "       [3.7104076e-07, 9.8718864e-01, 3.1256841e-03, 2.3832961e-03,\n",
       "        2.6620697e-05, 1.0607373e-04, 3.7545928e-05, 3.8218894e-03,\n",
       "        2.8234622e-03, 4.8646252e-04],\n",
       "       [1.7081934e-06, 4.0570208e-07, 1.2082874e-06, 1.4556614e-04,\n",
       "        9.7699422e-01, 6.1289496e-03, 4.8177124e-05, 9.4521325e-04,\n",
       "        8.8119823e-03, 6.9225961e-03],\n",
       "       [2.2009846e-07, 3.5304886e-03, 4.7808705e-04, 1.6286039e-03,\n",
       "        8.6856605e-03, 6.9202632e-03, 1.5752089e-04, 2.2809051e-03,\n",
       "        5.3472538e-03, 9.7097105e-01],\n",
       "       [4.4336429e-04, 2.6553454e-07, 3.4122297e-04, 2.2788083e-08,\n",
       "        1.8478147e-03, 1.0915616e-03, 9.9602783e-01, 2.3958808e-08,\n",
       "        2.3671894e-04, 1.1239443e-05],\n",
       "       [4.7576741e-06, 5.9267231e-09, 1.0077169e-06, 3.5155472e-06,\n",
       "        2.6632112e-02, 4.5605968e-05, 2.4033882e-06, 3.7676271e-02,\n",
       "        4.8200106e-03, 9.3081439e-01]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Raw predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 6 9]\n"
     ]
    }
   ],
   "source": [
    "# Print our model's predictions\n",
    "print(np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "# Check our predictions against the ground truths\n",
    "print(test_labels[:10]) # [7, 2, 1, 0, 4]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
