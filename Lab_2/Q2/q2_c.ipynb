{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Status: Active\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# check if GPU is being used\n",
    "print(\"GPU Status: \", end = '')\n",
    "if len(tf.config.list_physical_devices('GPU')) != 0: print(\"Active\")\n",
    "else: print(\"Inactive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import autokeras as ak\n",
    "\n",
    "#tf version should be 2.5 or higher\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get data\n",
    "(train_images, train_labels), (test_images, test_labels) = \\\n",
    "      keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape inputs for CNN layers\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# set hparams\n",
    "# HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'adagrad', 'rmsprop', 'sgd']))\n",
    "HP_CONV_UNITS = hp.HParam('conv_units', hp.Discrete([6, 12, 24]))\n",
    "HP_DENSE_UNITS = hp.HParam('dense_units', hp.Discrete([100, 200, 400]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hparams):\n",
    "\n",
    "  model = keras.Sequential([\n",
    "    keras.layers.Conv2D(kernel_size = 3, filters = hparams[HP_CONV_UNITS], use_bias = False, padding = 'same', input_shape = (28, 28, 1)),\n",
    "    keras.layers.BatchNormalization(center = True, scale = False),\n",
    "    keras.layers.Activation('gelu'),\n",
    "\n",
    "    keras.layers.Conv2D(kernel_size = 6, filters = 24, use_bias = False, padding = 'same', strides = 1),\n",
    "    keras.layers.BatchNormalization(center = True, scale = False),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(kernel_size = 6, filters = 32, use_bias = False, padding = 'same', strides = 1),\n",
    "    keras.layers.BatchNormalization(center = True, scale = False),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Conv2D(kernel_size = 6, filters = 32, use_bias = False, padding = 'same', strides = 1),\n",
    "    keras.layers.BatchNormalization(center = True, scale = False),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    keras.layers.Dense(hparams[HP_DENSE_UNITS], use_bias = False),\n",
    "    keras.layers.BatchNormalization(center = True, scale = False),\n",
    "    keras.layers.Activation('relu'),\n",
    "\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "  _, accuracy = model.evaluate(test_images, test_labels)\n",
    "  return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 16s 7ms/step - loss: 0.3679 - accuracy: 0.8692 - val_loss: 0.2695 - val_accuracy: 0.9028\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2477 - accuracy: 0.9090 - val_loss: 0.2326 - val_accuracy: 0.9135\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.2011 - accuracy: 0.9263 - val_loss: 0.2156 - val_accuracy: 0.9206\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1680 - accuracy: 0.9385 - val_loss: 0.2399 - val_accuracy: 0.9148\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1396 - accuracy: 0.9485 - val_loss: 0.2164 - val_accuracy: 0.9241\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.1113 - accuracy: 0.9594 - val_loss: 0.2138 - val_accuracy: 0.9287\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0873 - accuracy: 0.9672 - val_loss: 0.2324 - val_accuracy: 0.9249\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0696 - accuracy: 0.9748 - val_loss: 0.2369 - val_accuracy: 0.9254\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0562 - accuracy: 0.9800 - val_loss: 0.2431 - val_accuracy: 0.9298\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0456 - accuracy: 0.9839 - val_loss: 0.2635 - val_accuracy: 0.9276\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2635 - accuracy: 0.9276\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.3497 - accuracy: 0.8723 - val_loss: 0.2736 - val_accuracy: 0.8956\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2401 - accuracy: 0.9132 - val_loss: 0.2492 - val_accuracy: 0.9069\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1935 - accuracy: 0.9289 - val_loss: 0.2408 - val_accuracy: 0.9128\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1529 - accuracy: 0.9428 - val_loss: 0.2196 - val_accuracy: 0.9212\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1195 - accuracy: 0.9565 - val_loss: 0.2102 - val_accuracy: 0.9279\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0891 - accuracy: 0.9677 - val_loss: 0.2322 - val_accuracy: 0.9251\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0654 - accuracy: 0.9765 - val_loss: 0.2493 - val_accuracy: 0.9290\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0500 - accuracy: 0.9822 - val_loss: 0.2464 - val_accuracy: 0.9239\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0382 - accuracy: 0.9868 - val_loss: 0.2934 - val_accuracy: 0.9263\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 0.2920 - val_accuracy: 0.9283\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2920 - accuracy: 0.9283\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3535 - accuracy: 0.8726 - val_loss: 0.2716 - val_accuracy: 0.9024\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.2313 - accuracy: 0.9151 - val_loss: 0.2365 - val_accuracy: 0.9127\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.1839 - accuracy: 0.9326 - val_loss: 0.2534 - val_accuracy: 0.9079\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1465 - accuracy: 0.9462 - val_loss: 0.2376 - val_accuracy: 0.9172\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1092 - accuracy: 0.9598 - val_loss: 0.2148 - val_accuracy: 0.9313\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0785 - accuracy: 0.9719 - val_loss: 0.2549 - val_accuracy: 0.9236\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0564 - accuracy: 0.9797 - val_loss: 0.2595 - val_accuracy: 0.9286\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0421 - accuracy: 0.9850 - val_loss: 0.2848 - val_accuracy: 0.9284\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.3085 - val_accuracy: 0.9275\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 8ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.3428 - val_accuracy: 0.9283\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3428 - accuracy: 0.9283\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3593 - accuracy: 0.8728 - val_loss: 0.3032 - val_accuracy: 0.8860\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2473 - accuracy: 0.9104 - val_loss: 0.2429 - val_accuracy: 0.9093\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2022 - accuracy: 0.9264 - val_loss: 0.2607 - val_accuracy: 0.9042\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1727 - accuracy: 0.9364 - val_loss: 0.2179 - val_accuracy: 0.9185\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1417 - accuracy: 0.9482 - val_loss: 0.2045 - val_accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1158 - accuracy: 0.9573 - val_loss: 0.2200 - val_accuracy: 0.9207\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0925 - accuracy: 0.9661 - val_loss: 0.2247 - val_accuracy: 0.9280\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0735 - accuracy: 0.9730 - val_loss: 0.2295 - val_accuracy: 0.9297\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0585 - accuracy: 0.9787 - val_loss: 0.2323 - val_accuracy: 0.9280\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0489 - accuracy: 0.9833 - val_loss: 0.2476 - val_accuracy: 0.9285\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2476 - accuracy: 0.9285\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3600 - accuracy: 0.8697 - val_loss: 0.2743 - val_accuracy: 0.8989\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2362 - accuracy: 0.9129 - val_loss: 0.2378 - val_accuracy: 0.9146\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1936 - accuracy: 0.9284 - val_loss: 0.2208 - val_accuracy: 0.9172\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1562 - accuracy: 0.9423 - val_loss: 0.2093 - val_accuracy: 0.9261\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1221 - accuracy: 0.9554 - val_loss: 0.2154 - val_accuracy: 0.9279\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0945 - accuracy: 0.9650 - val_loss: 0.2336 - val_accuracy: 0.9264\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0731 - accuracy: 0.9730 - val_loss: 0.2598 - val_accuracy: 0.9264\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0516 - accuracy: 0.9816 - val_loss: 0.2328 - val_accuracy: 0.9311\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0430 - accuracy: 0.9848 - val_loss: 0.2705 - val_accuracy: 0.9288\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.0342 - accuracy: 0.9880 - val_loss: 0.2951 - val_accuracy: 0.9280\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2951 - accuracy: 0.9280\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3520 - accuracy: 0.8736 - val_loss: 0.2659 - val_accuracy: 0.9046\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2320 - accuracy: 0.9148 - val_loss: 0.2616 - val_accuracy: 0.9030\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1870 - accuracy: 0.9320 - val_loss: 0.2131 - val_accuracy: 0.9229\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1527 - accuracy: 0.9430 - val_loss: 0.2133 - val_accuracy: 0.9254\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1179 - accuracy: 0.9563 - val_loss: 0.2035 - val_accuracy: 0.9324\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0884 - accuracy: 0.9675 - val_loss: 0.2480 - val_accuracy: 0.9259\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0612 - accuracy: 0.9780 - val_loss: 0.2561 - val_accuracy: 0.9285\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 0.2356 - val_accuracy: 0.9255\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 0.2757 - val_accuracy: 0.9321\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.2974 - val_accuracy: 0.9305\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.9305\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3525 - accuracy: 0.8754 - val_loss: 0.3346 - val_accuracy: 0.8728\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2426 - accuracy: 0.9123 - val_loss: 0.2329 - val_accuracy: 0.9164\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1981 - accuracy: 0.9291 - val_loss: 0.2240 - val_accuracy: 0.9151\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1668 - accuracy: 0.9388 - val_loss: 0.2167 - val_accuracy: 0.9204\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1372 - accuracy: 0.9492 - val_loss: 0.2155 - val_accuracy: 0.9221\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1112 - accuracy: 0.9596 - val_loss: 0.2464 - val_accuracy: 0.9146\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0874 - accuracy: 0.9682 - val_loss: 0.2178 - val_accuracy: 0.9307\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0676 - accuracy: 0.9761 - val_loss: 0.2303 - val_accuracy: 0.9289\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0577 - accuracy: 0.9788 - val_loss: 0.2582 - val_accuracy: 0.9213\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0470 - accuracy: 0.9833 - val_loss: 0.2639 - val_accuracy: 0.9280\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2639 - accuracy: 0.9280\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.3482 - accuracy: 0.8748 - val_loss: 0.2602 - val_accuracy: 0.9027\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2352 - accuracy: 0.9131 - val_loss: 0.2407 - val_accuracy: 0.9109\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1913 - accuracy: 0.9301 - val_loss: 0.2603 - val_accuracy: 0.9057\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1564 - accuracy: 0.9429 - val_loss: 0.2482 - val_accuracy: 0.9086\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1243 - accuracy: 0.9544 - val_loss: 0.2160 - val_accuracy: 0.9293\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0969 - accuracy: 0.9641 - val_loss: 0.2005 - val_accuracy: 0.9322\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0715 - accuracy: 0.9739 - val_loss: 0.2297 - val_accuracy: 0.9335\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0569 - accuracy: 0.9798 - val_loss: 0.2506 - val_accuracy: 0.9329\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0406 - accuracy: 0.9859 - val_loss: 0.2487 - val_accuracy: 0.9315\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0326 - accuracy: 0.9890 - val_loss: 0.2704 - val_accuracy: 0.9322\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.9322\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.3533 - accuracy: 0.8713 - val_loss: 0.2804 - val_accuracy: 0.8926\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.2344 - accuracy: 0.9137 - val_loss: 0.2340 - val_accuracy: 0.9107\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1907 - accuracy: 0.9299 - val_loss: 0.2424 - val_accuracy: 0.9127\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1553 - accuracy: 0.9428 - val_loss: 0.2216 - val_accuracy: 0.9227\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1196 - accuracy: 0.9567 - val_loss: 0.2300 - val_accuracy: 0.9227\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0891 - accuracy: 0.9682 - val_loss: 0.2181 - val_accuracy: 0.9272\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0654 - accuracy: 0.9768 - val_loss: 0.2508 - val_accuracy: 0.9262\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0485 - accuracy: 0.9829 - val_loss: 0.2627 - val_accuracy: 0.9279\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0370 - accuracy: 0.9867 - val_loss: 0.2708 - val_accuracy: 0.9299\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0294 - accuracy: 0.9899 - val_loss: 0.2701 - val_accuracy: 0.9307\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.9307\n"
     ]
    }
   ],
   "source": [
    "num_conv_units = []\n",
    "num_dense_units = []\n",
    "units_accuracy = []\n",
    "\n",
    "for conv_units in HP_CONV_UNITS.domain.values:\n",
    "    for dense_units in HP_DENSE_UNITS.domain.values:\n",
    "        hparams = { \n",
    "            HP_CONV_UNITS: conv_units,\n",
    "            HP_DENSE_UNITS: dense_units,\n",
    "        }\n",
    "        accuracy = train_model(hparams)\n",
    "        num_conv_units.append(conv_units)\n",
    "        num_dense_units.append(dense_units)\n",
    "        units_accuracy.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 6\n",
      "DENSE Layer Units: 100\n",
      "Accuracy: 0.9276000261306763\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 6\n",
      "DENSE Layer Units: 200\n",
      "Accuracy: 0.9283000230789185\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 6\n",
      "DENSE Layer Units: 400\n",
      "Accuracy: 0.9283000230789185\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 12\n",
      "DENSE Layer Units: 100\n",
      "Accuracy: 0.9284999966621399\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 12\n",
      "DENSE Layer Units: 200\n",
      "Accuracy: 0.9279999732971191\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 12\n",
      "DENSE Layer Units: 400\n",
      "Accuracy: 0.9304999709129333\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 24\n",
      "DENSE Layer Units: 100\n",
      "Accuracy: 0.9279999732971191\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 24\n",
      "DENSE Layer Units: 200\n",
      "Accuracy: 0.932200014591217\n",
      "---------------------------------------------------------------------------\n",
      "---------------------------------------------------------------------------\n",
      "CONV Layer Filters: 24\n",
      "DENSE Layer Units: 400\n",
      "Accuracy: 0.9307000041007996\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range (9):\n",
    "        print(\"---------------------------------------------------------------------------\")\n",
    "        print(\"CONV Layer Filters: \" + str(num_conv_units[i]))\n",
    "        print(\"DENSE Layer Units: \" + str(num_dense_units[i]))\n",
    "        print(\"Accuracy: \" + str(units_accuracy[i]))\n",
    "        print(\"---------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
